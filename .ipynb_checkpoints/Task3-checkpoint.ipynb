{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task C Neural network (NN) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read the original data and show its basic inforamtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('wine_2020.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4000 non-null   float64\n",
      " 1   volatile acidity      4000 non-null   float64\n",
      " 2   critric acid          4000 non-null   float64\n",
      " 3   residual sugar        4000 non-null   float64\n",
      " 4   chlorides             4000 non-null   float64\n",
      " 5   free sulfur dioxide   4000 non-null   float64\n",
      " 6   total sulfur dioxide  4000 non-null   float64\n",
      " 7   density               4000 non-null   float64\n",
      " 8   pH                    4000 non-null   float64\n",
      " 9   sulphates             4000 non-null   float64\n",
      " 10  alcohol               4000 non-null   float64\n",
      " 11  quality               4000 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 375.1 KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()\n",
    "#non missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we can see there no missing value and outliers need to preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 11)\n"
     ]
    }
   ],
   "source": [
    "#SCALE\n",
    "x = raw_data.iloc[:,:-1]\n",
    "x = x.div(x.max()).values\n",
    "\n",
    "y = raw_data.iloc[:,-1]\n",
    "y = y.div(y.max()).values.reshape(-1,1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Scale by maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train _test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "X_train.info()\n",
    "#2800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Neural Network\n",
    "## parameter 3 layer，input layer size 11，hidden layer 10，out layer 1\n",
    "#active function segmoid\n",
    "#alpha 0.00001\n",
    "input_layer_size= 11\n",
    "hidden_layer_size= 10\n",
    "output_layer_size= 1\n",
    "\n",
    "# initialize the weights parameters\n",
    "np.random.seed(0)\n",
    "W1= np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W2= np.random.randn(hidden_layer_size, output_layer_size)\n",
    "# define learning rate of gradient descent\n",
    "alpha= 0.0001\n",
    "\n",
    "a1 = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#scale\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3 steps \n",
    "#1. forward propagation to get loss function\n",
    "#2. back propagation to updated weight\n",
    "#3. gradient descent to get best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define active function\n",
    "def sigmoid(x):\n",
    "    # our activation function: f(x) = 1 / (1 * e^(-x))\n",
    "    return (1 / (1+ np.exp(-x)))\n",
    "\n",
    "def sigmoidDerivationx(y):\n",
    "    return (y * (1 - y))\n",
    "\n",
    "def test_error(loss):\n",
    "    #for i in range(len(pred)):\n",
    "        #result = result + (pred[i] - test[i])**2/2\n",
    "    return np.sum(np.power(loss,2))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "delta3 = (a3-np.array(y_train).reshape(-1,1))*sigmoidDerivationx(z3)\n",
    "dW2 = a2.T.dot(delta3)\n",
    "delta2 = (delta3.dot(W2.T))*sigmoidDerivationx(z2)\n",
    "dw1 = a1.T.dot(delta2)\n",
    "# 10x10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propagation\n",
    "#loss function \n",
    "\n",
    "def forward(inputs,weight1,weight2):\n",
    "    z2 = np.dot(inputs,weight1) \n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(a2,weight2)\n",
    "    a3 = sigmoid(z3)#最后的结果 但是没有做loss\n",
    "    return a2,a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back propagation\n",
    "def backward(forward,inputs):\n",
    "    delta3 = (forward[1]-y)*sigmoidDerivationx(forward[1])\n",
    "    dW2 = np.dot(forward[0].T,delta3)#forward[2].T.dot(delta3)\n",
    "    delta2 = (delta3*W2.T)*sigmoidDerivationx(forward[0])\n",
    "    dW1 = np.dot(a1.T,delta2)\n",
    "    return dW1,dW2\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(weight1,weight2,dW1,dW2,alpha):\n",
    "    newW1 = weight1 - alpha*dW1\n",
    "    newW2 = weight2 - alpha*dW2\n",
    "    return newW1,newW2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store loss for plot\n",
    "loss_set=[]\n",
    "for i in range(10000):\n",
    "    result_forward = forward(a1,W1,W2)\n",
    "    #loss = result_forward[1]-y\n",
    "    result_backward = backward(result_forward,a1)\n",
    "    result_gradient = gradient_descent(W1,W2,result_backward[0],result_backward[1],alpha)\n",
    "    W1 = result_gradient[0]\n",
    "    W2 = result_gradient[1]\n",
    "    result_forward_new = forward(a1,W1,W2)\n",
    "    loss = result_forward_new[1]-y\n",
    "    loss_set.append(test_error(loss))  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#one iteration\n",
    "#再用新的dw1 dw2 去run fo\n",
    "#先试一次\n",
    "result_forward = forward(a1,W1,W2)\n",
    "result_backward = backward(result_forward,a1)\n",
    "result_gradient = gradient_descent(W1,W2,result_backward[0],result_backward[1],alpha)\n",
    "result_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "%time\n",
    "#iteration = 10000\n",
    "\n",
    "for i in range(10000):\n",
    "    result_forward = forward(a1,W1,W2)\n",
    "    result_backward = backward(result_forward,a1)\n",
    "    result_gradient = gradient_descent(W1,W2,result_backward[0],result_backward[1],alpha)\n",
    "    W1 = result_gradient[0]\n",
    "    W2 = result_gradient[1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "loss_set1=[]\n",
    "for i in range(10000):\n",
    "    z2 = np.dot(a1,W1) \n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(a2,W2)\n",
    "    a3 = sigmoid(z3)#最后的结果 但是没有做loss\n",
    "    \n",
    "    \n",
    "    delta3 = (a3-y)*sigmoidDerivationx(a3)\n",
    "    dW2 = a2.T.dot(delta3)\n",
    "    delta2 = (delta3*W2.T)*sigmoidDerivationx(a2)\n",
    "    dW1 = a1.T.dot(delta2)\n",
    "    \n",
    "    \n",
    "    W1 = W1 - alpha*dW1\n",
    "    W2 = W2 - alpha*dW2\n",
    "    \n",
    "    z2 = np.dot(a1,W1)\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(a2,W2)\n",
    "    a3 = sigmoid(z3)\n",
    "    loss = a3 - y\n",
    "    \n",
    "    loss_set1.append(test_error(loss))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(1,10001),loss_set)\n",
    "plt.show()\n",
    "#alpha可以更小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.724770301894573"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_set[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73704807],\n",
       "       [ 1.26593371],\n",
       "       [-2.2746167 ],\n",
       "       [ 1.11868777],\n",
       "       [-0.66899316],\n",
       "       [ 0.43559584],\n",
       "       [ 1.05454494],\n",
       "       [-0.32888345],\n",
       "       [ 0.17833581],\n",
       "       [ 0.95878048]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(1,10001),loss_set1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(result_forward[1],y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimising width of hidden layer \n",
    "#parameter\n",
    "## Initialize Neural Network\n",
    "## parameter 3 layer，input layer size 11，hidden layer 10，out layer 1\n",
    "#active function segmoid\n",
    "#alpha 0.00001\n",
    "input_layer_size= 11\n",
    "hidden_layer_size= 10\n",
    "output_layer_size= 1\n",
    "\n",
    "# initialize the weights parameters\n",
    "np.random.seed(0)\n",
    "W1= np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W2= np.random.randn(hidden_layer_size, output_layer_size)\n",
    "# define learning rate of gradient descent\n",
    "alpha= 0.0001\n",
    "\n",
    "a1 = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先单独optimize hidden layer\n",
    "#2-20\n",
    "loss_opt_hidden = []\n",
    "loss_opt_hidden_width = []\n",
    "\n",
    "for i in range(2,20):\n",
    "    #set parameter\n",
    "    input_layer_size= 11\n",
    "    hidden_layer_size= i\n",
    "    output_layer_size= 1\n",
    "    np.random.seed(0)\n",
    "    W1= np.random.randn(input_layer_size, hidden_layer_size)\n",
    "    W2= np.random.randn(hidden_layer_size, output_layer_size)\n",
    "    #set alpha\n",
    "    alpha= 0.0001\n",
    "    #set a1 = feature dataset\n",
    "    a1 = x    \n",
    "    for i in range(10000):\n",
    "        result_forward = forward(a1,W1,W2)\n",
    "        #loss = result_forward[1]-y\n",
    "        result_backward = backward(result_forward,a1)\n",
    "        result_gradient = gradient_descent(W1,W2,result_backward[0],result_backward[1],alpha)\n",
    "        W1 = result_gradient[0]\n",
    "        W2 = result_gradient[1]\n",
    "        result_forward_new = forward(a1,W1,W2)\n",
    "        loss = result_forward_new[1]-y\n",
    "        loss_opt_hidden.append(test_error(loss))\n",
    "    #collect loss result of different hidden layers\n",
    "    loss_opt_hidden_width.append(test_error(loss))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.369504607973028,\n",
       " 14.429753548333306,\n",
       " 12.10813556559531,\n",
       " 13.132096940788983,\n",
       " 8.558097193532056,\n",
       " 10.930116031758962,\n",
       " 12.616876019644252,\n",
       " 8.656806600523883,\n",
       " 8.724770301894573,\n",
       " 9.28149040377264,\n",
       " 10.250277115087579,\n",
       " 10.341821192681207,\n",
       " 7.697531687461851,\n",
       " 8.34395281254696,\n",
       " 8.069916513977095,\n",
       " 8.022512431675745,\n",
       " 9.79480871007922,\n",
       " 8.580191411049114]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss_opt_hidden_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optmize hidden and \n",
    "#alpha[0.001,0.0001,0.00001]\n",
    "#input_layer_size= 11\n",
    "#hidden_layer_size= 10\n",
    "#output_layer_size= 1\n",
    "\n",
    "# initialize the weights parameters\n",
    "#np.random.seed(0)\n",
    "#W1= np.random.randn(input_layer_size, hidden_layer_size)\n",
    "#W2= np.random.randn(hidden_layer_size, output_layer_size)\n",
    "# define learning rate of gradient descent\n",
    "alpha_list = [0.001,0.0001,0.00001]\n",
    "\n",
    "a1 = x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_opt_hidden_alpha = []\n",
    "loss_opt_hidden_alpha_width =[]\n",
    "#loss_opt_alpha_width = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    for i in range(8,15):\n",
    "    #set parameter\n",
    "        input_layer_size= 11\n",
    "        hidden_layer_size= i\n",
    "        output_layer_size= 1 \n",
    "        \n",
    "        np.random.seed(0)\n",
    "        W1= np.random.randn(input_layer_size, hidden_layer_size)\n",
    "        W2= np.rand om.randn(hidden_layer_size, output_layer_size)\n",
    "        \n",
    "        a1 = x \n",
    "        #set alpha\n",
    "        #alpha= 0.0001\n",
    "        #set a1 = feature dataset\n",
    "        \n",
    "        for i in range(10000):\n",
    "            result_forward = forward(a1,W1,W2)\n",
    "            #loss = result_forward[1]-y\n",
    "            result_backward = backward(result_forward,a1)\n",
    "            result_gradient = gradient_descent(W1,W2,result_backward[0],result_backward[1],alpha)\n",
    "            W1 = result_gradient[0]\n",
    "            W2 = result_gradient[1]\n",
    "            result_forward_new = forward(a1,W1,W2)\n",
    "            loss = result_forward_new[1]-y\n",
    "            loss_opt_hidden_alpha.append(test_error(loss))\n",
    "    #collect loss result of different hidden layers\n",
    "        #loss_opt_hidden_alpha_width.append(test_error(loss))\n",
    "        #loss_opt_alpha_width.append(test_error(loss))\n",
    "    #loss_opt_alpha_width.append(loss_opt_hidden_alpha_width)#min\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.852495414105665"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss_opt_hidden_alpha\n",
    "loss_opt_hidden_alpha_width[np.argmin(loss_opt_hidden_alpha_width)]\n",
    "#3x7个\n",
    "#loss_opt_alpha_width\n",
    "#loss_opt_alpha_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.881535849418781,\n",
       " 5.904113231945676,\n",
       " 5.897594225513176,\n",
       " 5.852495414105665,\n",
       " 5.893300793903121,\n",
       " 5.930785352608968,\n",
       " 5.860268303505123,\n",
       " 12.616876019644252,\n",
       " 8.656806600523883,\n",
       " 8.724770301894573,\n",
       " 9.28149040377264,\n",
       " 10.250277115087579,\n",
       " 10.341821192681207,\n",
       " 7.697531687461851,\n",
       " 18.86251301238394,\n",
       " 15.432017618704762,\n",
       " 20.230777368763505,\n",
       " 19.602193860125993,\n",
       " 15.323631261248966,\n",
       " 20.737340312461328,\n",
       " 21.93805798559456]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_opt_hidden_alpha_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "##opt alpha + hidden + iteration\n",
    "#optmize hidden and \n",
    "#alpha[0.001,0.0001,0.00001]\n",
    "#input_layer_size= 11\n",
    "#hidden_layer_size= 10\n",
    "#output_layer_size= 1\n",
    "\n",
    "# initialize the weights parameters\n",
    "#np.random.seed(0)\n",
    "#W1= np.random.randn(input_layer_size, hidden_layer_size)\n",
    "#W2= np.random.randn(hidden_layer_size, output_layer_size)\n",
    "# define learning rate of gradient descent\n",
    "alpha_list = [0.001,0.0001,0.00001]\n",
    "iteration_list = [1000,5000,10000,20000,50000]\n",
    "a1 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_opt_iterate = []\n",
    "loss_opt_iterate_width =[]\n",
    "#loss_opt_iterate_width = []\n",
    "\n",
    "for iterate in iteration_list:\n",
    "    for alpha in alpha_list:\n",
    "        for i in range(8,15):\n",
    "    #set parameter\n",
    "            input_layer_size= 11\n",
    "            hidden_layer_size= i\n",
    "            output_layer_size= 1 \n",
    "        \n",
    "            np.random.seed(0)\n",
    "            W1= np.random.randn(input_layer_size, hidden_layer_size)\n",
    "            W2= np.random.randn(hidden_layer_size, output_layer_size)\n",
    "        \n",
    "            a1 = x \n",
    "        #set alpha\n",
    "        #alpha= 0.0001\n",
    "        #set a1 = feature dataset        \n",
    "            for i in range(iterate):\n",
    "                result_forward = forward(a1,W1,W2)\n",
    "            #loss = result_forward[1]-y\n",
    "                result_backward = backward(result_forward,a1)\n",
    "                result_gradient = gradient_descent(W1,W2,result_backward[0],result_backward[1],alpha)\n",
    "                W1 = result_gradient[0]\n",
    "                W2 = result_gradient[1]\n",
    "                result_forward_new = forward(a1,W1,W2)\n",
    "                loss = result_forward_new[1]-y\n",
    "                loss_opt_iterate.append(test_error(loss))\n",
    "    #collect loss result of different hidden layers\n",
    "            loss_opt_iterate_width.append(test_error(loss))#7x3x5 个\n",
    "        #loss_opt_alpha_width.append(test_error(loss))\n",
    "    #loss_opt_alpha_width.append(loss_opt_hidden_alpha_width)#min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[12.61792319,  8.6578018 ,  8.72741097,  9.28334899,\n",
       "         10.25274534, 10.3438457 ,  7.69045101],\n",
       "        [18.86180108, 15.43068427, 20.23138648, 19.60109555,\n",
       "         15.32414919, 20.73578471, 21.93971908],\n",
       "        [23.71750602, 27.20014225, 32.61510362, 28.52342006,\n",
       "         16.64672021, 34.63583812, 34.89587684]],\n",
       "\n",
       "       [[ 6.12681203,  6.09656728,  5.95376287,  5.9784545 ,\n",
       "          6.12355779,  6.03021698,  6.02413488],\n",
       "        [14.38362202, 10.30244413, 11.51331437, 11.56201728,\n",
       "         12.09295935, 13.10445806, 10.12157887],\n",
       "        [20.95621044, 19.4810575 , 24.83797748, 23.35470854,\n",
       "         16.00356202, 25.23771422, 27.18961106]],\n",
       "\n",
       "       [[ 5.88153585,  5.90411323,  5.89759423,  5.85249541,\n",
       "          5.89330079,  5.93078535,  5.8602683 ],\n",
       "        [12.61687602,  8.6568066 ,  8.7247703 ,  9.2814904 ,\n",
       "         10.25027712, 10.34182119,  7.69753169],\n",
       "        [18.86251301, 15.43201762, 20.23077737, 19.60219386,\n",
       "         15.32363126, 20.73734031, 21.93805799]],\n",
       "\n",
       "       [[ 5.76193475,  5.76518566,  5.85051813,  5.77209355,\n",
       "          5.78392781,  5.85331482,  5.7404897 ],\n",
       "        [ 9.53737518,  7.03868992,  6.65176067,  7.07567847,\n",
       "          8.00443912,  7.3137772 ,  6.69069314],\n",
       "        [16.69308006, 12.55728832, 16.1061846 , 15.59652399,\n",
       "         14.21630206, 16.98052729, 16.72450025]],\n",
       "\n",
       "       [[ 5.61969405,  5.60651167,  5.69217852,  5.6371402 ,\n",
       "          5.6352304 ,  5.71008131,  5.6132252 ],\n",
       "        [ 6.12663945,  6.09655577,  5.9535116 ,  5.97842796,\n",
       "          6.12397773,  6.03002953,  6.02294177],\n",
       "        [14.38368911, 10.30238259, 11.51258737, 11.56195108,\n",
       "         12.09273087, 13.10440902, 10.12289678]]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_opt_iterate \n",
    "np.argmin(loss_opt_iterate_width)\n",
    "\n",
    "np.reshape(loss_opt_iterate_width, (5,3,7))\n",
    "\n",
    "#best parameter\n",
    "#hidden layer = 9\n",
    "#alpha = 0.001\n",
    "#iter = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
